{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Face detection is based on 68 face landmark points like eye, brows, lips, nose, and mouth. It these landmarks points matches with the landmark of a general face then that can be considered as a \"face\". \n",
    "\n",
    "On the other hand, face detection relies on 128 points or face embeddings. These face embeddings are used to compare our face with the embeddings that we already have in the database.\n",
    "\n",
    "In order to compare two faces perfectly, the face should be aligned. It should not be tilted or it should not be looking down or tilted to any side, so that it can compare with maximum efficiency. If not aligned , we have to align it by using different transformation techniques like translation, scaling, and rotation.\n",
    "\n",
    "* Translation: image is shifting from a particular position to the next position without changing any height or widht.\n",
    "* Scaling: image is changing the height or widht.\n",
    "* Rotation: image is changing the angle/orientation of the image.\n",
    "\n",
    "Once the alignment is complete the face will be perfectly okay for extracting the 128 features, which can call it as 128 dimensions of embeddings, which are different between image of different faces. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the image to detect\n",
    "original_image = cv2.imread('../Images/Testing/Dufflo and Banerjee.jpg')\n",
    "\n",
    "# Load the image to detect\n",
    "dufflo_image = face_recognition.load_image_file(\"../Images/Sample/Dufflo.jpg\")\n",
    "\n",
    "# Extract face encodings. It returns a list of 128-dimensional face encodings.\n",
    "dufflo_face_encoding = face_recognition.face_encodings(dufflo_image)[0]\n",
    "\n",
    "banerjee_image = face_recognition.load_image_file(\"../Images/Sample/Banerjee.jpg\")\n",
    "banerjee_face_encoding = face_recognition.face_encodings(banerjee_image)[0]\n",
    "\n",
    "# Create an array to save the encodings\n",
    "known_face_encodings = [dufflo_face_encoding, banerjee_face_encoding]\n",
    "\n",
    "# Create an array to hold labels\n",
    "known_face_names = [\"Dufflo\", \"Banerjee\"]\n",
    "\n",
    "# Load an unknown image to identify the faces\n",
    "image_to_recognize = face_recognition.load_image_file(\"../Images/Testing/Dufflo and Banerjee.jpg\")\n",
    "\n",
    "# Find all the faces and encodings in the unknown image\n",
    "all_face_locations = face_recognition.face_locations(image_to_recognize, number_of_times_to_upsample = 2, model = \"hog\")\n",
    "all_face_encodings = face_recognition.face_encodings(image_to_recognize, all_face_locations)\n",
    "\n",
    "# Print the number of faces detected\n",
    "print(\"There are {} number of face in this image\".format(len(all_face_locations)))\n",
    "\n",
    "# Looping through the face locations and the face embeddings\n",
    "for current_face_location, current_face_encoding in zip(all_face_locations, all_face_encodings):\n",
    "    # Splitting the tuple to get the 4 position values of current face\n",
    "    top_position, right_position, bottom_position, left_position = current_face_location\n",
    "    # Find all the matches and get the list of matches\n",
    "    all_matches = face_recognition.compare_faces(known_face_encodings, current_face_encoding)\n",
    "    # String to hold the label\n",
    "    name_of_person = 'Unknown face'\n",
    "    # Check if the all matches have at least one item. If yes, get the index number of face that is located in the first index of all_matches\n",
    "    if True in all_matches:\n",
    "        first_match_index = all_matches.index(True)\n",
    "        name_of_person = known_face_names[first_match_index]\n",
    "    # Draw rectangle around the face detected\n",
    "    cv2.rectangle(original_image, (left_position, top_position), (right_position, bottom_position), (255, 0, 0), 2)\n",
    "    # Display the name\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(original_image, name_of_person, (left_position, bottom_position), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "    # Display the image\n",
    "    cv2.imshow(\"Faces identified\", original_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video from real time webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2 number of face in this image\n"
     ]
    }
   ],
   "source": [
    "# Capture the video from default camera\n",
    "webcam_video_stream = cv2.VideoCapture(0)\n",
    "\n",
    "# Load the sample images and get the 128 face embeddings from them\n",
    "dufflo_image = face_recognition.load_image_file(\"../Images/Sample/Dufflo.jpg\")\n",
    "dufflo_face_encoding = face_recognition.face_encodings(dufflo_image)[0]\n",
    "\n",
    "banerjee_image = face_recognition.load_image_file(\"../Images/Sample/Banerjee.jpg\")\n",
    "banerjee_face_encoding = face_recognition.face_encodings(banerjee_image)[0]\n",
    "\n",
    "modi_image = face_recognition.load_image_file(\"../Images/Sample/Modi.jpg\")\n",
    "modi_face_encoding = face_recognition.face_encodings(modi_image)[0]\n",
    "\n",
    "trump_image = face_recognition.load_image_file(\"../Images/Sample/Trump.jpg\")\n",
    "trump_face_encoding = face_recognition.face_encodings(trump_image)[0]\n",
    "\n",
    "# Save the encodings and the corresponding laels in separate ararys in the same order\n",
    "known_face_encodings = [dufflo_face_encoding, banerjee_face_encoding, modi_face_encoding, trump_face_encoding]\n",
    "known_face_names = [\"Dufflo\", \"Banerjee\", \"Modi\", \"Trump\"]\n",
    "\n",
    "# Initialize the array to hold all face locations, encodings and labels in the frame\n",
    "all_face_locations = []\n",
    "all_face_encodings = []\n",
    "all_face_names = []\n",
    "\n",
    "# Loop through every frame in the video\n",
    "while True:\n",
    "    # Get the current frame from the video stream as an image\n",
    "    ret, current_frame = webcam_video_stream.read()\n",
    "    # Resize the current frame to 1/4 size to proces faster\n",
    "    current_frame_small = cv2.resize(current_frame, (0, 0), fx = 0.25, fy = 0.25)\n",
    "    # Detect all faces in the image\n",
    "    all_face_locations = face_recognition.face_locations(current_frame_small, 2, model = \"hog\")\n",
    "    # Find all the faces and encodings in the unknown image\n",
    "    all_face_encodings = face_recognition.face_encodings(current_frame_small, all_face_locations)\n",
    "\n",
    "    # Looping through the face locations and the face embeddings\n",
    "    for current_face_location, current_face_encoding in zip(all_face_locations, all_face_encodings):\n",
    "        # Splitting the tuple to get the 4 position values of current face\n",
    "        top_position, right_position, bottom_position, left_position = current_face_location\n",
    "        # Change the position magnitude to fit the actual size video frame\n",
    "        top_position = top_position * 4\n",
    "        right_position = right_position * 4\n",
    "        bottom_position = bottom_position * 4\n",
    "        left_position = left_position * 4\n",
    "        # Find all the matches and get the list of matches\n",
    "        all_matches = face_recognition.compare_faces(known_face_encodings, current_face_encoding)\n",
    "        # String to hold the label\n",
    "        name_of_person = 'Unknown face'\n",
    "        # Check if the all matches have at least one item. If yes, get the index number of face that is located in the first index of all_matches\n",
    "        if True in all_matches:\n",
    "            first_match_index = all_matches.index(True)\n",
    "            name_of_person = known_face_names[first_match_index]\n",
    "        # Draw rectangle around the face detected\n",
    "        cv2.rectangle(current_frame, (left_position, top_position), (right_position, bottom_position), (255, 0, 0), 2)\n",
    "        # Display the name\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(current_frame, name_of_person, (left_position, bottom_position), font, 0.5, (255, 255, 255), 1)\n",
    "\n",
    "        # Display the image\n",
    "        cv2.imshow(\"Webcam video\", current_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release the stream and cam\n",
    "# Close all opencv windows open\n",
    "webcam_video_stream.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
