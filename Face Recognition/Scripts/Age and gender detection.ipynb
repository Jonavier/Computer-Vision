{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Age and gender detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a deep learning model as a background we can recognize the gender and the age of a face.\n",
    "\n",
    "One of the model used to detect gender and age was created and trained by Gil Levi and Tal Hassner. They used the Adidence dataset, which has 26,850 photos from 2,284 subjects. They classified, for gender between male and female, and for age in range of 0-2, 4-6, 8-13, 15-20, 25-32, 38-43, 48-53, 60-.\n",
    "\n",
    "The files used are:\n",
    "\n",
    "* Age classification Caffe model.\n",
    "* Age classification protext file.\n",
    "* Gender classification Caffe model.\n",
    "* Gender classification protext file.\n",
    "* Age classification Caffe model.\n",
    "\n",
    "Caffe is a Deep Learning framework, and protext is actually a configuration file which tell a Caffe model how the neural network want to be trained. After training the model, we will get the trained model in a file with extension .caffemodel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video from real time webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default webcam video\n",
    "webcam_video_stream = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize empty array for face locations\n",
    "all_face_locations = []\n",
    "\n",
    "# Loop through every frame in the video\n",
    "while True:\n",
    "    # Get the current frame from the video stream as an image\n",
    "    ret, current_frame = webcam_video_stream.read()\n",
    "    # Resize the current frame to 1/4 size to proces faster\n",
    "    current_frame_small = cv2.resize(current_frame, (0, 0), fx = 0.25, fy = 0.25)\n",
    "    # Detect all faces in the image\n",
    "    all_face_locations = face_recognition.face_locations(current_frame_small, model = \"hog\")\n",
    "\n",
    "    # Looping through the face locations\n",
    "    for index, current_face_location in enumerate(all_face_locations):\n",
    "        top_position, right_position, bottom_position, left_position = current_face_location\n",
    "        # Change the position magnitude to fit the actual size video frame\n",
    "        top_position = top_position * 4\n",
    "        right_position = right_position * 4\n",
    "        bottom_position = bottom_position * 4\n",
    "        left_position = left_position * 4\n",
    "\n",
    "        # Slicing the current face from main image\n",
    "        current_face_image = current_frame[top_position:bottom_position, left_position:right_position]\n",
    "\n",
    "        # The \"Age_Gender_Model_Mean_Values\" calculated by using the numpy.mean()\n",
    "        Age_Gender_Model_Mean_Values = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "        # Create the binary large object (blob) of our face slice\n",
    "        current_face_image_blob = cv2.dnn.blobFromImage(current_face_image, 1, (227, 227), Age_Gender_Model_Mean_Values)\n",
    "\n",
    "        ##################### Gender #####################\n",
    "\n",
    "        # Declare gender labels, protext and caffemodel file paths\n",
    "        gender_label_list = [\"Male\", \"Female\"]\n",
    "        gender_protext = ('../Models/Gender and age model/gender_deploy.prototxt')\n",
    "        gender_caffemodel = ('../Models/Gender and age model/gender_net.caffemodel')\n",
    "\n",
    "        # Create model from files and provide blob as input\n",
    "        gender_cov_net = cv2.dnn.readNet(gender_caffemodel, gender_protext)\n",
    "        gender_cov_net.setInput(current_face_image_blob) \n",
    "\n",
    "        # Get gender predictions and get label of maximum value returned item\n",
    "        gender_predictions = gender_cov_net.forward()\n",
    "        gender = gender_label_list[gender_predictions[0].argmax()]\n",
    "\n",
    "        ##################### Age #####################\n",
    "\n",
    "        # Declare age labels, protext and caffemodel file paths\n",
    "        age_label_list = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "        age_protext = ('../Models/Gender and age model/age_deploy.prototxt')\n",
    "        age_caffemodel = ('../Models/Gender and age model/age_net.caffemodel')\n",
    "\n",
    "        # Create model from files and provide blob as input\n",
    "        age_cov_net = cv2.dnn.readNet(age_caffemodel, age_protext)\n",
    "        age_cov_net.setInput(current_face_image_blob) \n",
    "\n",
    "        # Get gender predictions and get label of maximum value returned item\n",
    "        age_predictions = age_cov_net.forward()\n",
    "        age = age_label_list[age_predictions[0].argmax()]\n",
    "\n",
    "        # Draw rectangle around the face detected\n",
    "        cv2.rectangle(current_frame, (left_position, top_position), (right_position, bottom_position), (0, 0, 255), 2)\n",
    "\n",
    "        # Display the name as text in the image\n",
    "        font = cv2.FONT_HERSHEY_DUPLEX\n",
    "        cv2.putText(current_frame, gender + \" \" + age + \"years\", (left_position, bottom_position + 20), font, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "    # Showing the current fae with rectangle drawn\n",
    "    cv2.imshow(\"Webcam Video\", current_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcam_video_stream.release()\n",
    "cv2.destroyAllWindows() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image age and gender detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 faces in this image\n",
      "Found face 1 at top: 34, right: 174, bottom: 91, left: 117\n"
     ]
    }
   ],
   "source": [
    "# Load the image to detect\n",
    "image_detect = cv2.imread(\"../Images/Testing/Image 10.jpg\")\n",
    "\n",
    "# Detect all faces in the image\n",
    "all_face_locations = face_recognition.face_locations(image_detect, model = \"cnn\")\n",
    "\n",
    "# Print the number of faces detected\n",
    "print(\"There are {} faces in this image\".format(len(all_face_locations)))\n",
    "\n",
    "for index, current_face_location in enumerate(all_face_locations):\n",
    "    top_position, right_position, bottom_position, left_position = current_face_location\n",
    "    print(\"Found face {} at top: {}, right: {}, bottom: {}, left: {}\".format(index + 1, top_position, right_position, bottom_position, left_position))\n",
    "    current_face_image = image_detect[top_position:bottom_position, left_position:right_position]\n",
    "\n",
    "    # The \"Age_Gender_Model_Mean_Values\" calculated by using the numpy.mean()\n",
    "    Age_Gender_Model_Mean_Values = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "    # Create the binary large object (blob) of our face slice\n",
    "    current_face_image_blob = cv2.dnn.blobFromImage(current_face_image, 1, (227, 227), Age_Gender_Model_Mean_Values, swapRB=False)\n",
    "\n",
    "    ##################### Gender #####################\n",
    "\n",
    "    # Declare gender labels, protext and caffemodel file paths\n",
    "    gender_label_list = [\"Male\", \"Female\"]\n",
    "    gender_protext = ('../Models/Gender and age model/gender_deploy.prototxt')\n",
    "    gender_caffemodel = ('../Models/Gender and age model/gender_net.caffemodel')\n",
    "\n",
    "    # Create model from files and provide blob as input\n",
    "    gender_cov_net = cv2.dnn.readNet(gender_caffemodel, gender_protext)\n",
    "    gender_cov_net.setInput(current_face_image_blob) \n",
    "\n",
    "    # Get gender predictions and get label of maximum value returned item\n",
    "    gender_predictions = gender_cov_net.forward()\n",
    "    gender = gender_label_list[gender_predictions[0].argmax()]\n",
    "\n",
    "    ##################### Age #####################\n",
    "\n",
    "    # Declare age labels, protext and caffemodel file paths\n",
    "    age_label_list = [\"(0-2)\", \"(4-6)\", \"(8-12)\", \"(15-20)\", \"(25-32)\", \"(38-43)\", \"(48-53)\", \"(60-100)\"]\n",
    "    age_protext = ('../Models/Gender and age model/age_deploy.prototxt')\n",
    "    age_caffemodel = ('../Models/Gender and age model/age_net.caffemodel')\n",
    "\n",
    "    # Create model from files and provide blob as input\n",
    "    age_cov_net = cv2.dnn.readNet(age_caffemodel, age_protext)\n",
    "    age_cov_net.setInput(current_face_image_blob) \n",
    "\n",
    "    # Get gender predictions and get label of maximum value returned item\n",
    "    age_predictions = age_cov_net.forward()\n",
    "    age = age_label_list[age_predictions[0].argmax()]\n",
    "\n",
    "    # Draw rectangle around the face detected\n",
    "    cv2.rectangle(image_detect, (left_position, top_position), (right_position, bottom_position), (0, 0, 255), 2)\n",
    "\n",
    "    # Display the name as text in the image\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    cv2.putText(image_detect, gender + \" \" + age + \"years\", (left_position, bottom_position + 20), font, 0.5, (0, 255, 0), 1)\n",
    "\n",
    "# Showing the current fae with rectangle drawn\n",
    "cv2.imshow(\"Age and Gender\", image_detect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
