{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It consists in detect automatically the face location in an digital images or video.\n",
    "\n",
    "Two popular types of face detectors are HoG face detector and CNN based faced detector."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HoG face detector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram of Oriented Gradients (HoG) is generally used for object detection. It relies on distribution of intensity gradients or edge directions.\n",
    "\n",
    "Gradient is the direction of intensity change of a pixel.\n",
    "\n",
    "<font color = '#FB1405'>Pros</font> \n",
    "\n",
    "* Faster while using in CPU, very light weight.\n",
    "* Works under small occlusion. Occlusing means deforming of face like wearing a sunglass or a hat or a scarf.\n",
    "\n",
    "<font color = '#FB1405'>Cons</font> \n",
    "\n",
    "* Min size of face should be 80x80 px.\n",
    "* Does not work for side face or high extremes of non-frontal faces, like looking down or up.\n",
    "* Doen't work under heavy occlusion (sunglasses, hat/cap. scarf, beard, etc)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Face Detector"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method uses Object Detector with Convolutional Neural Network (CNN) based features.\n",
    "\n",
    "The training process is simple. No need for a large amount of training data.\n",
    "\n",
    "<font color = '#FB1405'>Pros</font> \n",
    "\n",
    "* Detect multiple face orientations.\n",
    "* Works with medium occlusion.\n",
    "* Fast on GPU.\n",
    "\n",
    "<font color = '#FB1405'>Cons</font> \n",
    "\n",
    "* Very slow on CPU."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digital images"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect = cv2.imread(\"../Images/Testing/trump-modi.jpg\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Print images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Image\", image_detect)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find a print total number of faces"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all face locations using face_locations() function. Model can be \"cnn\" or \"hog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_face_locations = face_recognition.face_locations(image_detect, number_of_times_to_upsample = 2, model = \"hog\")\n",
    "print(\"There are {} number of face in this image\".format(len(all_face_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_face_locations = face_recognition.face_locations(image_detect, number_of_times_to_upsample = 2, model = \"cnn\")\n",
    "print(\"There are {} number of face in this image\".format(len(all_face_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect_one_face = cv2.imread(\"../Images/Testing/One face.jpg\")\n",
    "all_face_locations = face_recognition.face_locations(image_detect_one_face, model = \"hog\")\n",
    "print(\"There are {} number of face in this image\".format(len(all_face_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect_one_face = cv2.imread(\"../Images/Testing/One face.jpg\")\n",
    "all_face_locations = face_recognition.face_locations(image_detect_one_face, model = \"cnn\")\n",
    "print(\"There are {} number of face in this image\".format(len(all_face_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect_two_faces = cv2.imread(\"../Images/Testing/Two faces.jpg\")\n",
    "all_face_locations = face_recognition.face_locations(image_detect_two_faces, number_of_times_to_upsample = 2, model = \"cnn\")\n",
    "print(\"Using CNN model, in image with 2 face, we identify there are {} number of face in this image\".format(len(all_face_locations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_detect_two_faces = cv2.imread(\"../Images/Testing/Two faces.jpg\")\n",
    "all_face_locations = face_recognition.face_locations(image_detect_two_faces, number_of_times_to_upsample = 2, model = \"hog\")\n",
    "print(\"Using HoG model, in image with 2 face, we identify there are {} number of face in this image\".format(len(all_face_locations)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 2-sided image, 0 and 1 faces is found for the HoG and CNN models, respectively. This result is associated with the fact that the images of the faces are not frontal. On the other hand, in the images with frontal faces, the appropriate number of faces is found in both the hog and cnn models."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Face location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, current_face_location in enumerate(all_face_locations):\n",
    "    top_position, right_position, bottom_position, left_position = current_face_location\n",
    "    print(\"Found face {} at top: {}, right: {}, bottom: {}, left: {}\".format(index + 1, top_position, right_position, bottom_position, left_position))\n",
    "    current_face_image = image_detect_two_faces[top_position:bottom_position, left_position:right_position]\n",
    "    cv2.imshow(\"Face no \" + str(index + 1), current_face_image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video from real time webcam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that case, we are not going to extract the faces, we are just trying to draw a rectangle around the face.\n",
    "\n",
    "The mechanism is very similar to detection from image with following changes:\n",
    "\n",
    "* Get the webcam video.\n",
    "* Loop through "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the default webcam video\n",
    "webcam_video_stream = cv2.VideoCapture(0)\n",
    "\n",
    "# Initialize empty array for face locations\n",
    "all_face_locations = []\n",
    "\n",
    "# Loop through every frame in the video\n",
    "while True:\n",
    "    # Get the current frame from the video stream as an image\n",
    "    ret, current_frame = webcam_video_stream.read()\n",
    "    # Resize the current frame to 1/4 size to proces faster\n",
    "    current_frame_small = cv2.resize(current_frame, (0, 0), fx = 0.25, fy = 0.25)\n",
    "    # Detect all faces in the image\n",
    "    all_face_locations = face_recognition.face_locations(current_frame_small, model = \"hog\")\n",
    "\n",
    "    # Looping through the face locations\n",
    "    for index, current_face_location in enumerate(all_face_locations):\n",
    "        top_position, right_position, bottom_position, left_position = current_face_location\n",
    "        # Change the position magnitude to fit the actual size video frame\n",
    "        top_position = top_position * 4\n",
    "        right_position = right_position * 4\n",
    "        bottom_position = bottom_position * 4\n",
    "        left_position = bottom_position * 4\n",
    "        # Printing the location of current face\n",
    "        print(\"Found face {} at top: {}, right: {}, bottom: {}, left: {}\".format(index + 1, top_position, right_position, bottom_position, left_position))\n",
    "        # Draw rectangle around the face detected\n",
    "        cv2.rectangle(current_frame, (left_position, top_position), (right_position, bottom_position), (0, 0, 255), 2)\n",
    "    # Showing the current fae with rectangle drawn\n",
    "    cv2.imshow(\"Webcam Video\", current_frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "webcam_video_stream.release()\n",
    "cv2.destroyAllWindows() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputerVision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
